<!DOCTYPE html>
<html>
	<head>
		<title>Research</title>
		<!-- link to main stylesheet -->
		<link rel="stylesheet" type="text/css" href="../css/main.css">
	</head>
	
	<body>
		<nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<li><a href="/research">Research</a></li>
	        	<li><a href="/teaching">Teaching</a></li>
    		</ul>
		</nav>
		<p><li>Here is my <a href="../NikhilHegde_resstmt.pdf">research statement</a></li></p>
		<h2>Current Projects</h2>
			<p>
			<ul>
				<li>Parallelizing super-fast eigensolver for HSS matrices.</li>
				<li>Optimizing variadic functions</li>
				<li>Parallel code generation for recursive linear algebra algorithms</li>
				<li>Resiliency of locks against unintended calls to lock release operations: SPAA'23 (collaborators: Dr. Milind Chabbi, Vivek Shahare) </li>
			</ul>
			</p>
			<h2>Past Projects</h2>
			<p>
			<ul>
				<li> <a href="https://bitbucket.org/plcl/d2p">D2P</a>: From Recursive Formulations to Distributed Memory Codes. This work is about auto-generation of distributed-memory implementations of shared-memory algorithms. <a href="https://dl.acm.org/citation.cfm?id=3356205">Paper (ACM DL)</a></li> 
				<br>(The technical report of a part of this project can be found <a href="https://docs.lib.purdue.edu/ecetr/492/">here</a>)
				<li> <a href="https://bitbucket.org/plcl/treelogy">SPIRIT</a> - A framework for creating distributed recursive tree applications. The source code is available under the DM folder of Treelogy sourcecode.
  <a href="https://dl.acm.org/authorize.cfm?key=N39440">Paper (ACM DL)</a></li>
				<li> <a href="https://bitbucket.org/plcl/treelogy">Treelogy</a> -  A Benchmark Suite and an Ontology for Tree Traversal Algorithms.
  <a href="https://ieeexplore.ieee.org/document/7975294">Paper (IEEE Xplore)</a></li>

				<li>Hybrid CPU-GPU scheduling and execution of tree traversals - Scheduling optimization for tree traversal algorithms executing on GPUs. <a href="https://dl.acm.org/citation.cfm?id=2926261">Paper (ACM DL)</a></li>
				<li>WaSP -  Ensemble-based, Warm-Starting Parameter Initialization for Training of Deep Neural Network Models.</li>
			</ul>
			</p>
	</body>
</html>
