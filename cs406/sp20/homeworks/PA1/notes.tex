\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{tabulary}
\usepackage{float}
\usepackage{lipsum}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{listings}
\lstset
{ %Formatting for code in appendix
    language=C,
    basicstyle=\small,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}
\usepackage{xcolor}
\lstset{escapeinside={<@}{@>}}
\usepackage[T1]{fontenc}
\usepackage[parfill]{parskip}
\newcommand{\code}[1]{\textsf{#1}}
\setlength{\parindent}{0em}
\begin{document}
\begin{center}{\LARGE CS406: Compilers} \end{center}
\begin{center}{\large Programming Assignment 1: Scanner,  Due: 29/1/2020} \end{center}

\bigskip



\section{Introduction}
The working of a scanner---sometimes called the tokenizer or lexical analyzer---forms the first phase of the compilation process. 
A scanner is a program that takes a sequence of characters (the source file of the program) and produces a sequence of tokens that will be used to feed the compiler's parser, the next phase of the compilation process.
So, for example, the input

\texttt{A := B + 4}

Would translate into the following tokens:

\texttt{IDENTIFIER (Value = "A")}

\texttt{OPERATOR (Value = ":=")}

\texttt{IDENTIFIER (Value = "B")}

\texttt{OPERATOR (Value = "+")}

\texttt{INTLITERAL (Value = "4")}

The way that we define tokens in a programming language is with {\em regular expressions}. For example, a regular expression that defines an integer literal token looks like: 

\texttt{[0-9]+} (read: "1 or more digits"),

while a regular expression that defines a float literal token looks like: 

\texttt{[0-9]+\.[0-9]* | \.[0-9]+} (read: "Either 1 or more digits followed by a decimal followed by 0 or more digits; or a decimal followed by 1 or more digits")

While you can write a scanner by hand, it is very tedious. Instead, we typically use tools to help us automatically generate scanners. The tools we recommend you to use are either flex (if you're planning on writing your compiler in C or C++) or ANTLR (if you're planning on writing your compiler in Java). flex is available on most Unixes/Linux (including the ecegrid machines), while ANTLR requires a download. If you want to use other tools to generate your scanner, feel free, but we will be able to provide less help.

\section{Token definitions}
We will be building a compiler for a simple language called MICRO in this class. The token definitions (written in plain English) are as follows:

\begin{lstlisting}[numbers=none]
an IDENTIFIER token will begin with a letter, and be followed by any number of letters and numbers. 
IDENTIFIERS are case sensitive.

INTLITERAL: integer number
           ex) 0, 123, 678

FLOATLITERAL: floating point number available in two different format
                yyyy.xxxxxx or .xxxxxxx
            ex) 3.141592 , .1414 , .0001 , 456.98

STRINGLITERAL: any sequence of characters except '"' 
            between '"' and '"' 
            ex) "Hello world!" , "***********" , "this is a string"

COMMENT:
      Starts with "#" and lasts till the end of line
      ex) # this is a comment
      ex) # any thing after the "#" is ignored 

Keywords

PROGRAM,BEGIN,END,FUNCTION,READ,WRITE,
IF,ELSE,FI,FOR,ROF,
RETURN,INT,VOID,STRING,FLOAT

Operators

:= + - * / = != < > ( ) ; , <= >=
\end{lstlisting}

\section{What you need to do}
You should build a scanner that will take an input file and output a list of all the tokens in the program. For each token, you should output the token type (e.g., \textsf{OPERATOR}) and its value (e.g., \textsf{+}).

There are sample \href{https://hegden.github.io/cs406/homeworks/PA1/inputs.zip}{inputs} and \href{https://hegden.github.io/cs406/homeworks/PA1/outputs.zip}{outputs} here. These are the only inputs we will test your compiler on. Your outputs need to match our outputs exactly (we will be comparing them using diff, though we will ignore whitespace).

\subsection{Hints}
Note that even though our sample outputs combine together a bunch of different tokens as a single type (e.g., all keywords have the token type \textsf{KEYWORD}), you will be better served by defining every keyword and operator as a {\em different} token type (so your scanner will have different tokens for, say, \textsf{:=} and \textsf{<}), and then writing a little bit of extra code to print the output we expect for that token type.

While it might seem weird, you {\em will} need to define a token that eats up any whitespace in your program (recall that your compiler really only sees a list of characters; it has no reason to think that a tab character isn't an important character). Make sure that when you recognize a whitespace token, you just silently drop it, rather than printing it out.

\subsection{What you need to submit}
\begin{itemize}
	\item All of the necessary code for your compiler that you wrote yourself. 

	\item A Makefile with the following targets:
		\begin{enumerate}
			\item compiler: this target will build your compiler
			\item clean: this target will remove any intermediate files that were created to build the compiler
			\item team: this target will print the same team information that you printed in step 0.
		\end{enumerate}
\end{itemize}

While you may create as many other directories as you would like to organize your code or any intermediate products of the compilation process, your \textsf{Makefile} should be in the root directory of your repository.

{\em Do not submit any binaries}. Your git repo should only contain source files; no products of compilation.

You should tag your programming assignment submission as \textsf{submission}
\end{document}
